# Housing Price Regression Analysis

Kaggle House Prices competition project using only classical regression models, focusing on data preprocessing, feature engineering, and constrained model design.

Competition link:
https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques

---

## Project Overview

This project presents an end-to-end housing price prediction workflow built for the Kaggle House Prices competition. The focus is not only predictive performance, but disciplined model design under constraints.

Only classical regression models were allowed. Advanced ensemble or deep learning methods were intentionally excluded to emphasize strong preprocessing, feature engineering, and statistical modeling fundamentals.

---

## Objectives

- Clean and preprocess raw housing data
- Perform exploratory data analysis (EDA)
- Engineer predictive features
- Build and evaluate regression models
- Improve generalization under modeling constraints
- Compare OLS with regularized regression approaches

---

## Models Used

- Ordinary Least Squares (OLS)
- Ridge Regression
- Lasso Regression
- ElasticNet Regression

No tree-based models, boosting, or neural networks were used.

---

## Key Results

The final enhanced model achieved strong predictive performance with high R² and low RMSE on unseen data. Cross-validation results remained consistent, indicating good generalization and low overfitting.

The project demonstrates how careful data preparation and feature engineering can rival more complex models when applied correctly.

---

## Repository Structure
- data → raw and processed datasets
- notebooks → Jupyter notebooks
- reports → exported HTML analysis

  ---

## Tools & Libraries

- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib / Seaborn
- Jupyter Notebook

---

## Author
Sara Alsiyat
